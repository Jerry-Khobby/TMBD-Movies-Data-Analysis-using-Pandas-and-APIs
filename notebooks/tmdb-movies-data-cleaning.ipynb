{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a17455",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-08T08:56:17.088939Z",
     "iopub.status.busy": "2025-12-08T08:56:17.088276Z",
     "iopub.status.idle": "2025-12-08T08:56:18.937834Z",
     "shell.execute_reply": "2025-12-08T08:56:18.936879Z"
    },
    "papermill": {
     "duration": 1.855547,
     "end_time": "2025-12-08T08:56:18.939554",
     "exception": false,
     "start_time": "2025-12-08T08:56:17.084007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import pandas as pd \n",
    "import matplotlib as plt \n",
    "import numpy as np \n",
    "import logging\n",
    "import json\n",
    "import warnings\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12111ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T08:56:18.945786Z",
     "iopub.status.busy": "2025-12-08T08:56:18.945365Z",
     "iopub.status.idle": "2025-12-08T08:56:18.950026Z",
     "shell.execute_reply": "2025-12-08T08:56:18.949099Z"
    },
    "papermill": {
     "duration": 0.009461,
     "end_time": "2025-12-08T08:56:18.951608",
     "exception": false,
     "start_time": "2025-12-08T08:56:18.942147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8e7d0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T08:56:18.957265Z",
     "iopub.status.busy": "2025-12-08T08:56:18.956970Z",
     "iopub.status.idle": "2025-12-08T08:56:18.961142Z",
     "shell.execute_reply": "2025-12-08T08:56:18.960285Z"
    },
    "papermill": {
     "duration": 0.00872,
     "end_time": "2025-12-08T08:56:18.962512",
     "exception": false,
     "start_time": "2025-12-08T08:56:18.953792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "406b857b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T08:56:18.967795Z",
     "iopub.status.busy": "2025-12-08T08:56:18.967465Z",
     "iopub.status.idle": "2025-12-08T08:56:19.008559Z",
     "shell.execute_reply": "2025-12-08T08:56:19.007493Z"
    },
    "papermill": {
     "duration": 0.045682,
     "end_time": "2025-12-08T08:56:19.010224",
     "exception": false,
     "start_time": "2025-12-08T08:56:18.964542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/9wXPKruA6b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/7JNzw1tSZZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/8BTsTfln4j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/mDfJG3LC3D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/xnHVX37XZE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/dF6FjTZzRT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/1TUg5pO1VZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/9BBTo63ANS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/ehzI1mVcnH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/kIBK5SKwgq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/b6ZJZHUdME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/cbcpDn6XJa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/5Iw7zQTHVR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/AoSZyb37lj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/gBmrsugfWp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/u2bZhH3nTf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/uU1Mt4JWhD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'adult': False, 'backdrop_path': '/mabuNsGJgR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0                                                 NaN\n",
       "1   {'adult': False, 'backdrop_path': '/9wXPKruA6b...\n",
       "2   {'adult': False, 'backdrop_path': '/7JNzw1tSZZ...\n",
       "3   {'adult': False, 'backdrop_path': '/8BTsTfln4j...\n",
       "4   {'adult': False, 'backdrop_path': '/mDfJG3LC3D...\n",
       "5   {'adult': False, 'backdrop_path': '/xnHVX37XZE...\n",
       "6   {'adult': False, 'backdrop_path': '/dF6FjTZzRT...\n",
       "7   {'adult': False, 'backdrop_path': '/1TUg5pO1VZ...\n",
       "8   {'adult': False, 'backdrop_path': '/9BBTo63ANS...\n",
       "9   {'adult': False, 'backdrop_path': '/ehzI1mVcnH...\n",
       "10  {'adult': False, 'backdrop_path': '/kIBK5SKwgq...\n",
       "11  {'adult': False, 'backdrop_path': '/b6ZJZHUdME...\n",
       "12  {'adult': False, 'backdrop_path': '/cbcpDn6XJa...\n",
       "13  {'adult': False, 'backdrop_path': '/5Iw7zQTHVR...\n",
       "14  {'adult': False, 'backdrop_path': '/AoSZyb37lj...\n",
       "15  {'adult': False, 'backdrop_path': '/gBmrsugfWp...\n",
       "16  {'adult': False, 'backdrop_path': '/u2bZhH3nTf...\n",
       "17  {'adult': False, 'backdrop_path': '/uU1Mt4JWhD...\n",
       "18  {'adult': False, 'backdrop_path': '/mabuNsGJgR..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/tmdb-raw/movies_raw.csv\")\n",
    "#pd.set_option('display.max_colwidth',50)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8366f450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T08:56:19.016329Z",
     "iopub.status.busy": "2025-12-08T08:56:19.016048Z",
     "iopub.status.idle": "2025-12-08T08:56:19.046257Z",
     "shell.execute_reply": "2025-12-08T08:56:19.045188Z"
    },
    "papermill": {
     "duration": 0.035185,
     "end_time": "2025-12-08T08:56:19.047867",
     "exception": false,
     "start_time": "2025-12-08T08:56:19.012682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19 entries, 0 to 18\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       18 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 284.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d16837",
   "metadata": {
    "papermill": {
     "duration": 0.002298,
     "end_time": "2025-12-08T08:56:19.052697",
     "exception": false,
     "start_time": "2025-12-08T08:56:19.050399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> # Master Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "629f148a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T08:56:19.059017Z",
     "iopub.status.busy": "2025-12-08T08:56:19.058696Z",
     "iopub.status.idle": "2025-12-08T08:56:19.077134Z",
     "shell.execute_reply": "2025-12-08T08:56:19.076240Z"
    },
    "papermill": {
     "duration": 0.023779,
     "end_time": "2025-12-08T08:56:19.078719",
     "exception": false,
     "start_time": "2025-12-08T08:56:19.054940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_movies_data(df: pd.DataFrame, validate: bool=True, log_path: str=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Step 2: Data Cleaning and Preprocessing for TMDB Movie Data\n",
    "    \n",
    "    This function performs:\n",
    "    - Conversion of nested JSON-like strings to proper Python objects\n",
    "    - Dropping irrelevant columns\n",
    "    - Extraction of key information from JSON-like columns\n",
    "    - Handling missing and incorrect data\n",
    "    - Replacement of unrealistic values\n",
    "    - Removing duplicates and filtering\n",
    "    - Column reordering and placeholders creation\n",
    "    - Resetting index and preparing the final clean dataset\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Raw TMDB movie dataframe\n",
    "        validate (bool): If True, logs column anomaly info\n",
    "        log_path (str): Optional path to save log file\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned movie dataframe ready for analysis\n",
    "    \"\"\"\n",
    "    import logging\n",
    "\n",
    "    # Create logger\n",
    "    logger = logging.getLogger(\"movie_cleaner\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # If writing to log file\n",
    "    if log_path:\n",
    "        handler = logging.FileHandler(log_path)\n",
    "    else:\n",
    "        handler = logging.StreamHandler()   # logs to console if no file provided\n",
    "\n",
    "    # Create log format\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    handler.setFormatter(formatter)\n",
    "\n",
    "    # Avoid duplicate handlers if function is called multiple times\n",
    "    if not logger.handlers:\n",
    "        logger.addHandler(handler)\n",
    "\n",
    "    logger.info(f\"Starting cleaning pipeline. Input shape: {df.shape}\")\n",
    "\n",
    "\n",
    "    logging.info(f\"Starting cleaning pipeline. Input shape: {df.shape}\")\n",
    "    # Step 2a: Convert to proper DataFrame\n",
    "    df = df[df.iloc[:,0].notna()] \n",
    "    df_dicts = df.iloc[:,0].apply(ast.literal_eval)\n",
    "    df = pd.json_normalize(df_dicts)\n",
    "    \n",
    "    # Step 2b: Drop irrelevant columns\n",
    "    cols_to_drop = ['adult', 'imdb_id', 'original_title', 'video', 'homepage']\n",
    "    df = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "    \n",
    "    # Step 2c: Convert JSON-like columns to proper objects\n",
    "    df['belongs_to_collection'] = df['belongs_to_collection'].apply(\n",
    "        lambda x: x if isinstance(x, dict) else ast.literal_eval(x) if isinstance(x, str) else {}\n",
    "    )\n",
    "    \n",
    "    json_cols = ['genres', 'production_countries', 'production_companies', 'spoken_languages']\n",
    "    for col in json_cols:\n",
    "        df[col] = df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "        df[col] = df[col].apply(lambda x: [] if x is None else x)\n",
    "    \n",
    "    # Step 2d: Extract key information\n",
    "    df['collection_name'] = df['belongs_to_collection'].apply(\n",
    "        lambda x: x.get('name', '') if isinstance(x, dict) else ''\n",
    "    )\n",
    "    df['genres'] = df['genres'].apply(lambda x: '|'.join([g['name'] for g in x]))\n",
    "    df['spoken_languages'] = df['spoken_languages'].apply(lambda x: '|'.join(d['english_name'] for d in x))\n",
    "    df['production_countries'] = df['production_countries'].apply(lambda x: '|'.join(c['name'] for c in x))\n",
    "    df['production_companies'] = df['production_companies'].apply(lambda x: '|'.join(c['name'] for c in x))\n",
    "    \n",
    "    # Step 2e: Inspect anomalies (optional)\n",
    "    if validate:\n",
    "        for col in ['collection_name', 'genres', 'spoken_languages', 'production_countries', 'production_companies']:\n",
    "            empty_count = df[col].isin([\"\", \"[]\", \"{}\"]).sum()\n",
    "            unique_vals = df[col].nunique()\n",
    "            logger.info(f\"Column '{col}': {empty_count} empty/placeholder values, {unique_vals} unique values\")\n",
    "    \n",
    "\n",
    "    # Step 2f: Convert column datatypes\n",
    "    df['budget'] = pd.to_numeric(df['budget'], errors='coerce')\n",
    "    df['id'] = pd.to_numeric(df['id'], errors='coerce')\n",
    "    df['popularity'] = pd.to_numeric(df['popularity'], errors='coerce')\n",
    "    df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "    \n",
    "    numeric_cols = ['revenue', 'vote_average', 'vote_count', 'belongs_to_collection.id']\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Step 2g: Replace unrealistic values\n",
    "    df[['budget', 'revenue', 'runtime']] = df[['budget', 'revenue', 'runtime']].replace(0, np.nan)\n",
    "    df['budget'] = df['budget'] / 1_000_000\n",
    "    df['revenue'] = df['revenue'] / 1_000_000\n",
    "    df.loc[df['vote_count'] == 0, 'vote_average'] = np.nan\n",
    "    \n",
    "    placeholder_texts = ['No Data', 'N/A', 'Unknown', '']\n",
    "    df['overview'] = df['overview'].replace(placeholder_texts, np.nan)\n",
    "    df['tagline'] = df['tagline'].replace(placeholder_texts, np.nan)\n",
    "    \n",
    "    # Step 2h: Remove duplicates and filter\n",
    "    df = df.drop_duplicates(subset=['id', 'title'])\n",
    "    df = df.dropna(thresh=10)\n",
    "    if 'status' in df.columns:\n",
    "        df = df[df['status'] == 'Released'].drop(columns=['status'])\n",
    "    \n",
    "    # Step 2i: Rename columns\n",
    "    df = df.rename(columns={'budget': 'budget_musd', 'revenue': 'revenue_musd'})\n",
    "    \n",
    "    # Step 2j: Create empty placeholders for missing columns\n",
    "    df['cast'] = [[]] * len(df)\n",
    "    df['cast_size'] = 0\n",
    "    df['director'] = [[]] * len(df)\n",
    "    df['crew_size'] = 0\n",
    "    \n",
    "    # Step 2k: Reorder columns\n",
    "    final_cols = [\n",
    "        'id', 'title', 'tagline', 'release_date', 'genres', 'belongs_to_collection',\n",
    "        'original_language', 'budget_musd', 'revenue_musd', 'production_companies',\n",
    "        'production_countries', 'vote_count', 'vote_average', 'popularity', 'runtime',\n",
    "        'overview', 'spoken_languages', 'poster_path', 'cast', 'cast_size', 'director', 'crew_size'\n",
    "    ]\n",
    "    df = df[[c for c in final_cols if c in df.columns]]\n",
    "    \n",
    "    # Step 2l: Reset index-\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    logger.info(\"Movie data cleaned successfully.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c1d6728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T08:56:19.085643Z",
     "iopub.status.busy": "2025-12-08T08:56:19.084738Z",
     "iopub.status.idle": "2025-12-08T08:56:19.143408Z",
     "shell.execute_reply": "2025-12-08T08:56:19.142371Z"
    },
    "papermill": {
     "duration": 0.064186,
     "end_time": "2025-12-08T08:56:19.145405",
     "exception": false,
     "start_time": "2025-12-08T08:56:19.081219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 08:56:19,090 [INFO] Starting cleaning pipeline. Input shape: (19, 1)\n",
      "2025-12-08 08:56:19,091 [INFO] Starting cleaning pipeline. Input shape: (19, 1)\n",
      "2025-12-08 08:56:19,108 [INFO] Column 'collection_name': 18 empty/placeholder values, 1 unique values\n",
      "2025-12-08 08:56:19,110 [INFO] Column 'genres': 0 empty/placeholder values, 14 unique values\n",
      "2025-12-08 08:56:19,111 [INFO] Column 'spoken_languages': 0 empty/placeholder values, 10 unique values\n",
      "2025-12-08 08:56:19,112 [INFO] Column 'production_countries': 0 empty/placeholder values, 3 unique values\n",
      "2025-12-08 08:56:19,114 [INFO] Column 'production_companies': 0 empty/placeholder values, 13 unique values\n",
      "2025-12-08 08:56:19,133 [INFO] Movie data cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('/kaggle/input/tmdb-raw/movies_raw.csv')\n",
    "cleaned_df = clean_movies_data(df, validate=True, log_path=\"cleaning.log\")\n",
    "cleaned_df.to_csv(\"tmdb_movies_clean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8916396,
     "sourceId": 13989073,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.501176,
   "end_time": "2025-12-08T08:56:19.667477",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-08T08:56:12.166301",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
